{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":1335058,"sourceType":"datasetVersion","datasetId":775267}],"dockerImageVersionId":30627,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -q mamba-ssm\n!pip install -q causal-conv1d","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-12-16T23:59:04.064646Z","iopub.execute_input":"2023-12-16T23:59:04.064943Z","iopub.status.idle":"2023-12-17T00:00:01.122627Z","shell.execute_reply.started":"2023-12-16T23:59:04.064916Z","shell.execute_reply":"2023-12-17T00:00:01.121353Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import torch\nimport time\nfrom mamba_ssm.models.mixer_seq_simple import MambaLMHeadModel","metadata":{"execution":{"iopub.status.busy":"2023-12-17T00:00:01.124609Z","iopub.execute_input":"2023-12-17T00:00:01.124947Z","iopub.status.idle":"2023-12-17T00:00:05.576633Z","shell.execute_reply.started":"2023-12-17T00:00:01.124921Z","shell.execute_reply":"2023-12-17T00:00:05.575736Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# config\ntorch.manual_seed(11)\ndevice = \"cuda\"","metadata":{"execution":{"iopub.status.busy":"2023-12-17T00:00:05.577642Z","iopub.execute_input":"2023-12-17T00:00:05.578051Z","iopub.status.idle":"2023-12-17T00:00:05.586343Z","shell.execute_reply.started":"2023-12-17T00:00:05.578024Z","shell.execute_reply":"2023-12-17T00:00:05.585463Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"with open(\"../input/for-use/shakespeare.txt\", \"r\") as f:\n    data = f.read()\nprint(data[:200])","metadata":{"execution":{"iopub.status.busy":"2023-12-17T00:00:05.588162Z","iopub.execute_input":"2023-12-17T00:00:05.588477Z","iopub.status.idle":"2023-12-17T00:00:05.644026Z","shell.execute_reply.started":"2023-12-17T00:00:05.588446Z","shell.execute_reply":"2023-12-17T00:00:05.643093Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"First Citizen:\nBefore we proceed any further, hear me speak.\n\nAll:\nSpeak, speak.\n\nFirst Citizen:\nYou are all resolved rather to die than to famish?\n\nAll:\nResolved. resolved.\n\nFirst Citizen:\nFirst, you\n","output_type":"stream"}]},{"cell_type":"code","source":"chars = sorted(list(set(data)))\nvocab_size = len(chars)\n\ninput_size = 1024\nbatch_size = 4\n\nc2i = {c: i for i, c in enumerate(chars)}\ni2c = {i: c for i, c in enumerate(chars)}\n\nencode = lambda s: [c2i[c] for c in s]\ndecode = lambda l: \"\".join([i2c[i] for i in l])\n\ndata_ = torch.tensor(encode(data), dtype=torch.long)\nn = int(len(data_) * 0.9)\n\ntrain_data = data_[:n]\nval_data = data_[n:]","metadata":{"execution":{"iopub.status.busy":"2023-12-17T00:00:05.645388Z","iopub.execute_input":"2023-12-17T00:00:05.646033Z","iopub.status.idle":"2023-12-17T00:00:05.967226Z","shell.execute_reply.started":"2023-12-17T00:00:05.645996Z","shell.execute_reply":"2023-12-17T00:00:05.966421Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"def get_batch(split):\n    data = train_data if split == \"train\" else val_data\n    ix = torch.randint(len(data) - input_size, (batch_size,))\n    x = torch.stack([data[i : i + input_size] for i in ix])\n    y = torch.stack([data[i + 1 : i + input_size + 1] for i in ix])\n    x, y = x.pin_memory().to(device, non_blocking=True), y.pin_memory().to(device, non_blocking=True)\n    return x, y\n\nmodel = MambaLMHeadModel(d_model=768,n_layer=12,vocab_size=vocab_size,device=device)\nn_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\noptimizer = torch.optim.AdamW(model.parameters(), lr=0.001)\nloss_fct = torch.nn.CrossEntropyLoss()","metadata":{"execution":{"iopub.status.busy":"2023-12-17T00:00:05.968298Z","iopub.execute_input":"2023-12-17T00:00:05.968598Z","iopub.status.idle":"2023-12-17T00:00:09.457356Z","shell.execute_reply.started":"2023-12-17T00:00:05.968573Z","shell.execute_reply":"2023-12-17T00:00:09.456584Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# training\nt_start = time.time()\nmax_iters = 1000\nprint_interval = 100\nfor iter in range(max_iters):\n    xb, yb = get_batch(\"train\")\n    logits = model(xb).logits\n    B, T, C = logits.shape\n    logits = logits.view(B * T, C)\n    yb = yb.view(B * T)\n    loss = loss_fct(logits, yb)\n    optimizer.zero_grad(set_to_none=True)\n    loss.backward()\n    optimizer.step()\n\n    if iter % print_interval == 0:\n        print('Iteration {} loss: {}'.format(iter + 1, loss.item()))\n\nprint(\"\\n\")\nprint(f\"Number of parameters: {n_params}\")\nprint(f\"Training time:        {(time.time() - t_start)/60:.2f} min\")","metadata":{"execution":{"iopub.status.busy":"2023-12-17T00:00:09.458510Z","iopub.execute_input":"2023-12-17T00:00:09.458804Z","iopub.status.idle":"2023-12-17T00:00:12.458331Z","shell.execute_reply.started":"2023-12-17T00:00:09.458778Z","shell.execute_reply":"2023-12-17T00:00:12.456867Z"},"trusted":true},"execution_count":7,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[7], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28miter\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(max_iters):\n\u001b[1;32m      6\u001b[0m     xb, yb \u001b[38;5;241m=\u001b[39m get_batch(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 7\u001b[0m     logits \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxb\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mlogits\n\u001b[1;32m      8\u001b[0m     B, T, C \u001b[38;5;241m=\u001b[39m logits\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m      9\u001b[0m     logits \u001b[38;5;241m=\u001b[39m logits\u001b[38;5;241m.\u001b[39mview(B \u001b[38;5;241m*\u001b[39m T, C)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/mamba_ssm/models/mixer_seq_simple.py:221\u001b[0m, in \u001b[0;36mMambaLMHeadModel.forward\u001b[0;34m(self, input_ids, position_ids, inference_params, num_last_tokens)\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, input_ids, position_ids\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, inference_params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, num_last_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[1;32m    217\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;124;03m    \"position_ids\" is just to be compatible with Transformer generation. We don't use it.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;124;03m    num_last_tokens: if > 0, only return the logits for the last n tokens\u001b[39;00m\n\u001b[1;32m    220\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 221\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackbone\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minference_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minference_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    222\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m num_last_tokens \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    223\u001b[0m         hidden_states \u001b[38;5;241m=\u001b[39m hidden_states[:, \u001b[38;5;241m-\u001b[39mnum_last_tokens:]\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/mamba_ssm/models/mixer_seq_simple.py:152\u001b[0m, in \u001b[0;36mMixerModel.forward\u001b[0;34m(self, input_ids, inference_params)\u001b[0m\n\u001b[1;32m    150\u001b[0m residual \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[0;32m--> 152\u001b[0m     hidden_states, residual \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    153\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresidual\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minference_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minference_params\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfused_add_norm:\n\u001b[1;32m    156\u001b[0m     residual \u001b[38;5;241m=\u001b[39m (hidden_states \u001b[38;5;241m+\u001b[39m residual) \u001b[38;5;28;01mif\u001b[39;00m residual \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m hidden_states\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/mamba_ssm/modules/mamba_simple.py:350\u001b[0m, in \u001b[0;36mBlock.forward\u001b[0;34m(self, hidden_states, residual, inference_params)\u001b[0m\n\u001b[1;32m    340\u001b[0m     fused_add_norm_fn \u001b[38;5;241m=\u001b[39m rms_norm_fn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm, RMSNorm) \u001b[38;5;28;01melse\u001b[39;00m layer_norm_fn\n\u001b[1;32m    341\u001b[0m     hidden_states, residual \u001b[38;5;241m=\u001b[39m fused_add_norm_fn(\n\u001b[1;32m    342\u001b[0m         hidden_states,\n\u001b[1;32m    343\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm\u001b[38;5;241m.\u001b[39mweight,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    348\u001b[0m         eps\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm\u001b[38;5;241m.\u001b[39meps,\n\u001b[1;32m    349\u001b[0m     )\n\u001b[0;32m--> 350\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmixer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minference_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minference_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m hidden_states, residual\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/mamba_ssm/modules/mamba_simple.py:149\u001b[0m, in \u001b[0;36mMamba.forward\u001b[0;34m(self, hidden_states, inference_params)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;66;03m# In the backward pass we write dx and dz next to each other to avoid torch.cat\u001b[39;00m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_fast_path \u001b[38;5;129;01mand\u001b[39;00m inference_params \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:  \u001b[38;5;66;03m# Doesn't support outputting the states\u001b[39;00m\n\u001b[0;32m--> 149\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mmamba_inner_fn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    150\u001b[0m \u001b[43m        \u001b[49m\u001b[43mxz\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1d\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    152\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1d\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    153\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx_proj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdt_proj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mout_proj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mout_proj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[43m        \u001b[49m\u001b[43mA\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# input-dependent B\u001b[39;49;00m\n\u001b[1;32m    159\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# input-dependent C\u001b[39;49;00m\n\u001b[1;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mD\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdelta_bias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdt_proj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdelta_softplus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    165\u001b[0m     x, z \u001b[38;5;241m=\u001b[39m xz\u001b[38;5;241m.\u001b[39mchunk(\u001b[38;5;241m2\u001b[39m, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/mamba_ssm/ops/selective_scan_interface.py:306\u001b[0m, in \u001b[0;36mmamba_inner_fn\u001b[0;34m(xz, conv1d_weight, conv1d_bias, x_proj_weight, delta_proj_weight, out_proj_weight, out_proj_bias, A, B, C, D, delta_bias, B_proj_bias, C_proj_bias, delta_softplus)\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmamba_inner_fn\u001b[39m(\n\u001b[1;32m    301\u001b[0m     xz, conv1d_weight, conv1d_bias, x_proj_weight, delta_proj_weight,\n\u001b[1;32m    302\u001b[0m     out_proj_weight, out_proj_bias,\n\u001b[1;32m    303\u001b[0m     A, B\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, C\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, D\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, delta_bias\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, B_proj_bias\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    304\u001b[0m     C_proj_bias\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, delta_softplus\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    305\u001b[0m ):\n\u001b[0;32m--> 306\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mMambaInnerFn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxz\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconv1d_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconv1d_bias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_proj_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdelta_proj_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    307\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mout_proj_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_proj_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    308\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mA\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mB\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mC\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mD\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdelta_bias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mB_proj_bias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mC_proj_bias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdelta_softplus\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/autograd/function.py:506\u001b[0m, in \u001b[0;36mFunction.apply\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    503\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_are_functorch_transforms_active():\n\u001b[1;32m    504\u001b[0m     \u001b[38;5;66;03m# See NOTE: [functorch vjp and autograd interaction]\u001b[39;00m\n\u001b[1;32m    505\u001b[0m     args \u001b[38;5;241m=\u001b[39m _functorch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39munwrap_dead_wrappers(args)\n\u001b[0;32m--> 506\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m    508\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39msetup_context \u001b[38;5;241m==\u001b[39m _SingleLevelFunction\u001b[38;5;241m.\u001b[39msetup_context:\n\u001b[1;32m    509\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    510\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIn order to use an autograd.Function with functorch transforms \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    511\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m(vmap, grad, jvp, jacrev, ...), it must override the setup_context \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    512\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstaticmethod. For more details, please see \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    513\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://pytorch.org/docs/master/notes/extending.func.html\u001b[39m\u001b[38;5;124m'\u001b[39m)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/cuda/amp/autocast_mode.py:98\u001b[0m, in \u001b[0;36mcustom_fwd.<locals>.decorate_fwd\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cast_inputs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     97\u001b[0m     args[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39m_fwd_used_autocast \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mis_autocast_enabled()\n\u001b[0;32m---> 98\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfwd\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    100\u001b[0m     autocast_context \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mis_autocast_enabled()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/mamba_ssm/ops/selective_scan_interface.py:181\u001b[0m, in \u001b[0;36mMambaInnerFn.forward\u001b[0;34m(ctx, xz, conv1d_weight, conv1d_bias, x_proj_weight, delta_proj_weight, out_proj_weight, out_proj_bias, A, B, C, D, delta_bias, B_proj_bias, C_proj_bias, delta_softplus, checkpoint_lvl)\u001b[0m\n\u001b[1;32m    179\u001b[0m x, z \u001b[38;5;241m=\u001b[39m xz\u001b[38;5;241m.\u001b[39mchunk(\u001b[38;5;241m2\u001b[39m, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    180\u001b[0m conv1d_bias \u001b[38;5;241m=\u001b[39m conv1d_bias\u001b[38;5;241m.\u001b[39mcontiguous() \u001b[38;5;28;01mif\u001b[39;00m conv1d_bias \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 181\u001b[0m conv1d_out \u001b[38;5;241m=\u001b[39m \u001b[43mcausal_conv1d_cuda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcausal_conv1d_fwd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconv1d_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconv1d_bias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;66;03m# We're being very careful here about the layout, to avoid extra transposes.\u001b[39;00m\n\u001b[1;32m    183\u001b[0m \u001b[38;5;66;03m# We want delta to have d as the slowest moving dimension\u001b[39;00m\n\u001b[1;32m    184\u001b[0m \u001b[38;5;66;03m# and L as the fastest moving dimension, since those are what the ssm_scan kernel expects.\u001b[39;00m\n\u001b[1;32m    185\u001b[0m x_dbl \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mlinear(rearrange(conv1d_out, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mb d l -> (b l) d\u001b[39m\u001b[38;5;124m'\u001b[39m), x_proj_weight)  \u001b[38;5;66;03m# (bl d)\u001b[39;00m\n","\u001b[0;31mTypeError\u001b[0m: causal_conv1d_fwd(): incompatible function arguments. The following argument types are supported:\n    1. (arg0: torch.Tensor, arg1: torch.Tensor, arg2: Optional[torch.Tensor], arg3: Optional[torch.Tensor], arg4: bool) -> torch.Tensor\n\nInvoked with: tensor([[[-0.4288, -0.7415,  0.2338,  ...,  0.4696, -0.7415,  0.1994],\n         [-0.2644,  0.9622, -0.7267,  ..., -0.2105,  0.9622, -0.5146],\n         [-1.2545, -0.0087,  0.3420,  ...,  0.3833, -0.0087,  0.5425],\n         ...,\n         [-0.0883, -0.8732,  0.4167,  ...,  0.7703, -0.8732,  0.5065],\n         [-0.3103,  0.1674, -0.9188,  ..., -0.4987,  0.1674, -0.6746],\n         [ 0.0817,  0.1187,  0.4305,  ...,  0.2771,  0.1187, -0.6790]],\n\n        [[ 0.4696,  0.3384,  0.5967,  ...,  0.2312, -0.6446, -0.5635],\n         [-0.2105, -0.9218,  0.6288,  ..., -0.8121,  0.4196, -0.1247],\n         [ 0.3833, -0.1912, -0.0106,  ...,  0.5447,  0.8804, -0.5389],\n         ...,\n         [ 0.7703, -0.0258, -0.0229,  ...,  0.5308, -0.0322, -0.6238],\n         [-0.4987,  1.0386, -0.5600,  ..., -0.3423, -0.3097,  0.6895],\n         [ 0.2771, -0.1353,  0.4125,  ...,  0.3521, -0.4873, -0.0586]],\n\n        [[ 0.3327, -0.5635,  0.4696,  ..., -0.9914, -0.7415,  0.3327],\n         [-0.4432, -0.1247, -0.2105,  ..., -0.6084,  0.9622, -0.4432],\n         [ 0.0035, -0.5389,  0.3833,  ..., -0.5454, -0.0087,  0.0035],\n         ...,\n         [-0.3613, -0.6238,  0.7703,  ...,  0.2984, -0.8732, -0.3613],\n         [ 0.2868,  0.6895, -0.4987,  ..., -0.9830,  0.1674,  0.2868],\n         [-0.2470, -0.0586,  0.2771,  ..., -0.0096,  0.1187, -0.2470]],\n\n        [[ 0.4696,  0.3327, -0.6446,  ..., -0.7415, -0.4288, -0.9914],\n         [-0.2105, -0.4432,  0.4196,  ...,  0.9622, -0.2644, -0.6084],\n         [ 0.3833,  0.0035,  0.8804,  ..., -0.0087, -1.2545, -0.5454],\n         ...,\n         [ 0.7703, -0.3613, -0.0322,  ..., -0.8732, -0.0883,  0.2984],\n         [-0.4987,  0.2868, -0.3097,  ...,  0.1674, -0.3103, -0.9830],\n         [ 0.2771, -0.2470, -0.4873,  ...,  0.1187,  0.0817, -0.0096]]],\n       device='cuda:0', requires_grad=True), tensor([[ 0.1220,  0.0901,  0.0736,  0.1439],\n        [-0.0095, -0.1856,  0.4502,  0.1997],\n        [-0.2036, -0.0495,  0.3747, -0.0074],\n        ...,\n        [ 0.2265,  0.2769,  0.0143,  0.1760],\n        [ 0.0952,  0.1286,  0.1418, -0.4398],\n        [ 0.1948, -0.0843, -0.3106, -0.2859]], device='cuda:0',\n       requires_grad=True), Parameter containing:\ntensor([ 0.4892,  0.4341,  0.1342,  ...,  0.0411, -0.0503, -0.2879],\n       device='cuda:0', requires_grad=True), True"],"ename":"TypeError","evalue":"causal_conv1d_fwd(): incompatible function arguments. The following argument types are supported:\n    1. (arg0: torch.Tensor, arg1: torch.Tensor, arg2: Optional[torch.Tensor], arg3: Optional[torch.Tensor], arg4: bool) -> torch.Tensor\n\nInvoked with: tensor([[[-0.4288, -0.7415,  0.2338,  ...,  0.4696, -0.7415,  0.1994],\n         [-0.2644,  0.9622, -0.7267,  ..., -0.2105,  0.9622, -0.5146],\n         [-1.2545, -0.0087,  0.3420,  ...,  0.3833, -0.0087,  0.5425],\n         ...,\n         [-0.0883, -0.8732,  0.4167,  ...,  0.7703, -0.8732,  0.5065],\n         [-0.3103,  0.1674, -0.9188,  ..., -0.4987,  0.1674, -0.6746],\n         [ 0.0817,  0.1187,  0.4305,  ...,  0.2771,  0.1187, -0.6790]],\n\n        [[ 0.4696,  0.3384,  0.5967,  ...,  0.2312, -0.6446, -0.5635],\n         [-0.2105, -0.9218,  0.6288,  ..., -0.8121,  0.4196, -0.1247],\n         [ 0.3833, -0.1912, -0.0106,  ...,  0.5447,  0.8804, -0.5389],\n         ...,\n         [ 0.7703, -0.0258, -0.0229,  ...,  0.5308, -0.0322, -0.6238],\n         [-0.4987,  1.0386, -0.5600,  ..., -0.3423, -0.3097,  0.6895],\n         [ 0.2771, -0.1353,  0.4125,  ...,  0.3521, -0.4873, -0.0586]],\n\n        [[ 0.3327, -0.5635,  0.4696,  ..., -0.9914, -0.7415,  0.3327],\n         [-0.4432, -0.1247, -0.2105,  ..., -0.6084,  0.9622, -0.4432],\n         [ 0.0035, -0.5389,  0.3833,  ..., -0.5454, -0.0087,  0.0035],\n         ...,\n         [-0.3613, -0.6238,  0.7703,  ...,  0.2984, -0.8732, -0.3613],\n         [ 0.2868,  0.6895, -0.4987,  ..., -0.9830,  0.1674,  0.2868],\n         [-0.2470, -0.0586,  0.2771,  ..., -0.0096,  0.1187, -0.2470]],\n\n        [[ 0.4696,  0.3327, -0.6446,  ..., -0.7415, -0.4288, -0.9914],\n         [-0.2105, -0.4432,  0.4196,  ...,  0.9622, -0.2644, -0.6084],\n         [ 0.3833,  0.0035,  0.8804,  ..., -0.0087, -1.2545, -0.5454],\n         ...,\n         [ 0.7703, -0.3613, -0.0322,  ..., -0.8732, -0.0883,  0.2984],\n         [-0.4987,  0.2868, -0.3097,  ...,  0.1674, -0.3103, -0.9830],\n         [ 0.2771, -0.2470, -0.4873,  ...,  0.1187,  0.0817, -0.0096]]],\n       device='cuda:0', requires_grad=True), tensor([[ 0.1220,  0.0901,  0.0736,  0.1439],\n        [-0.0095, -0.1856,  0.4502,  0.1997],\n        [-0.2036, -0.0495,  0.3747, -0.0074],\n        ...,\n        [ 0.2265,  0.2769,  0.0143,  0.1760],\n        [ 0.0952,  0.1286,  0.1418, -0.4398],\n        [ 0.1948, -0.0843, -0.3106, -0.2859]], device='cuda:0',\n       requires_grad=True), Parameter containing:\ntensor([ 0.4892,  0.4341,  0.1342,  ...,  0.0411, -0.0503, -0.2879],\n       device='cuda:0', requires_grad=True), True","output_type":"error"}]},{"cell_type":"code","source":"prompt_tokens = torch.tensor(encode(\"Shall I compare thee to a summer's \"),dtype=torch.long, device=device).unsqueeze(1).T\nres_tokens = model.generate(prompt_tokens, max_length=200,top_k=10,top_p=1.0,temperature=1.1,cg=True)\nlist_chars = res_tokens.tolist()[0]\nprint(decode(list_chars))","metadata":{"execution":{"iopub.status.busy":"2023-12-17T00:00:20.789349Z","iopub.execute_input":"2023-12-17T00:00:20.790241Z","iopub.status.idle":"2023-12-17T00:00:21.364985Z","shell.execute_reply.started":"2023-12-17T00:00:20.790200Z","shell.execute_reply":"2023-12-17T00:00:21.363418Z"},"trusted":true},"execution_count":8,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","Cell \u001b[0;32mIn[8], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m prompt_tokens \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(encode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShall I compare thee to a summer\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms \u001b[39m\u001b[38;5;124m\"\u001b[39m),dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong, device\u001b[38;5;241m=\u001b[39mdevice)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mT\n\u001b[0;32m----> 2\u001b[0m res_tokens \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_tokens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mtop_k\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mtop_p\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1.1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mcg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m list_chars \u001b[38;5;241m=\u001b[39m res_tokens\u001b[38;5;241m.\u001b[39mtolist()[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(decode(list_chars))\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/mamba_ssm/utils/generation.py:218\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, input_ids, max_length, top_k, top_p, temperature, return_dict_in_generate, output_scores, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate\u001b[39m(\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    209\u001b[0m     input_ids,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    217\u001b[0m ):\n\u001b[0;32m--> 218\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    219\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_k\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtop_k\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    220\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m output_scores:\n\u001b[1;32m    222\u001b[0m         output\u001b[38;5;241m.\u001b[39mscores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/mamba_ssm/utils/generation.py:127\u001b[0m, in \u001b[0;36mdecode\u001b[0;34m(input_ids, model, max_length, top_k, top_p, temperature, eos_token_id, teacher_outputs, vocab_size, tensor_parallel, cg, enable_timing)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(model, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_decoding_cache\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    126\u001b[0m     model\u001b[38;5;241m.\u001b[39m_decoding_cache \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 127\u001b[0m model\u001b[38;5;241m.\u001b[39m_decoding_cache \u001b[38;5;241m=\u001b[39m \u001b[43mupdate_graph_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    129\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_decoding_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    130\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    131\u001b[0m \u001b[43m    \u001b[49m\u001b[43mseqlen_og\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    132\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    133\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensor_parallel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_parallel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    135\u001b[0m inference_params \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39m_decoding_cache\u001b[38;5;241m.\u001b[39minference_params\n\u001b[1;32m    136\u001b[0m inference_params\u001b[38;5;241m.\u001b[39mreset(max_length, batch_size)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/mamba_ssm/utils/generation.py:311\u001b[0m, in \u001b[0;36mupdate_graph_cache\u001b[0;34m(model, cache, batch_size, seqlen_og, max_seqlen, decoding_seqlens, tensor_parallel, dtype, n_warmups)\u001b[0m\n\u001b[1;32m    309\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m decoding_seqlen \u001b[38;5;129;01min\u001b[39;00m decoding_seqlens:\n\u001b[1;32m    310\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (batch_size, decoding_seqlen) \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m cache\u001b[38;5;241m.\u001b[39mcallables:\n\u001b[0;32m--> 311\u001b[0m         cache\u001b[38;5;241m.\u001b[39mcallables[batch_size, decoding_seqlen] \u001b[38;5;241m=\u001b[39m \u001b[43mcapture_graph\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    313\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcache\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minference_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    314\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    315\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmax_seqlen\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdecoding_seqlen\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoding_seqlen\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmempool\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmempool\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_warmups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_warmups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    319\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdispatch\u001b[39m(input_ids, position_ids, seqlen):\n\u001b[1;32m    322\u001b[0m     batch_size, decoding_seqlen \u001b[38;5;241m=\u001b[39m input_ids\u001b[38;5;241m.\u001b[39mshape[:\u001b[38;5;241m2\u001b[39m]\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/mamba_ssm/utils/generation.py:345\u001b[0m, in \u001b[0;36mcapture_graph\u001b[0;34m(model, inference_params, batch_size, max_seqlen, decoding_seqlen, mempool, n_warmups)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mstream(s):\n\u001b[1;32m    344\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_warmups):\n\u001b[0;32m--> 345\u001b[0m         logits \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    346\u001b[0m \u001b[43m            \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[43m            \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m            \u001b[49m\u001b[43minference_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minference_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnum_last_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoding_seqlen\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mlogits\n\u001b[1;32m    351\u001b[0m     s\u001b[38;5;241m.\u001b[39msynchronize()\n\u001b[1;32m    352\u001b[0m     \u001b[38;5;66;03m# This might be needed for correctness if we run with NCCL_GRAPH_MIXING_SUPPORT=0,\u001b[39;00m\n\u001b[1;32m    353\u001b[0m     \u001b[38;5;66;03m# which requires that graph launch and non-captured launch to not overlap (I think,\u001b[39;00m\n\u001b[1;32m    354\u001b[0m     \u001b[38;5;66;03m# that's how I interpret the documentation). I'm not sure if this is required.\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/mamba_ssm/models/mixer_seq_simple.py:221\u001b[0m, in \u001b[0;36mMambaLMHeadModel.forward\u001b[0;34m(self, input_ids, position_ids, inference_params, num_last_tokens)\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, input_ids, position_ids\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, inference_params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, num_last_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[1;32m    217\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;124;03m    \"position_ids\" is just to be compatible with Transformer generation. We don't use it.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;124;03m    num_last_tokens: if > 0, only return the logits for the last n tokens\u001b[39;00m\n\u001b[1;32m    220\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 221\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackbone\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minference_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minference_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    222\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m num_last_tokens \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    223\u001b[0m         hidden_states \u001b[38;5;241m=\u001b[39m hidden_states[:, \u001b[38;5;241m-\u001b[39mnum_last_tokens:]\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/mamba_ssm/models/mixer_seq_simple.py:152\u001b[0m, in \u001b[0;36mMixerModel.forward\u001b[0;34m(self, input_ids, inference_params)\u001b[0m\n\u001b[1;32m    150\u001b[0m residual \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[0;32m--> 152\u001b[0m     hidden_states, residual \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    153\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresidual\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minference_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minference_params\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfused_add_norm:\n\u001b[1;32m    156\u001b[0m     residual \u001b[38;5;241m=\u001b[39m (hidden_states \u001b[38;5;241m+\u001b[39m residual) \u001b[38;5;28;01mif\u001b[39;00m residual \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m hidden_states\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/mamba_ssm/modules/mamba_simple.py:350\u001b[0m, in \u001b[0;36mBlock.forward\u001b[0;34m(self, hidden_states, residual, inference_params)\u001b[0m\n\u001b[1;32m    340\u001b[0m     fused_add_norm_fn \u001b[38;5;241m=\u001b[39m rms_norm_fn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm, RMSNorm) \u001b[38;5;28;01melse\u001b[39;00m layer_norm_fn\n\u001b[1;32m    341\u001b[0m     hidden_states, residual \u001b[38;5;241m=\u001b[39m fused_add_norm_fn(\n\u001b[1;32m    342\u001b[0m         hidden_states,\n\u001b[1;32m    343\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm\u001b[38;5;241m.\u001b[39mweight,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    348\u001b[0m         eps\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm\u001b[38;5;241m.\u001b[39meps,\n\u001b[1;32m    349\u001b[0m     )\n\u001b[0;32m--> 350\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmixer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minference_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minference_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m hidden_states, residual\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/mamba_ssm/modules/mamba_simple.py:134\u001b[0m, in \u001b[0;36mMamba.forward\u001b[0;34m(self, hidden_states, inference_params)\u001b[0m\n\u001b[1;32m    131\u001b[0m     conv_state, ssm_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_states_from_cache(inference_params, batch)\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m inference_params\u001b[38;5;241m.\u001b[39mseqlen_offset \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    133\u001b[0m         \u001b[38;5;66;03m# The states are updated inplace\u001b[39;00m\n\u001b[0;32m--> 134\u001b[0m         out, _, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconv_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mssm_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    135\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m out\n\u001b[1;32m    137\u001b[0m \u001b[38;5;66;03m# We do matmul and transpose BLH -> HBL at the same time\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/mamba_ssm/modules/mamba_simple.py:224\u001b[0m, in \u001b[0;36mMamba.step\u001b[0;34m(self, hidden_states, conv_state, ssm_state)\u001b[0m\n\u001b[1;32m    222\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mact(x)\u001b[38;5;241m.\u001b[39mto(dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 224\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mcausal_conv1d_update\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    225\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    226\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconv_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    227\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrearrange\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1d\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43md 1 w -> d w\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    228\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1d\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    229\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mactivation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    230\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    232\u001b[0m x_db \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx_proj(x)  \u001b[38;5;66;03m# (B dt_rank+2*d_state)\u001b[39;00m\n\u001b[1;32m    233\u001b[0m dt, B, C \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msplit(x_db, [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdt_rank, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39md_state, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39md_state], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/causal_conv1d/causal_conv1d_interface.py:83\u001b[0m, in \u001b[0;36mcausal_conv1d_update\u001b[0;34m(x, conv_state, weight, bias, activation)\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mactivation must be None, silu, or swish\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     82\u001b[0m activation \u001b[38;5;241m=\u001b[39m activation \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msilu\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mswish\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m---> 83\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcausal_conv1d_cuda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcausal_conv1d_update\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconv_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactivation\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[0;31mRuntimeError\u001b[0m: CUDA error: no kernel image is available for execution on the device\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n\nException raised from c10_cuda_check_implementation at /usr/local/src/pytorch/c10/cuda/CUDAException.cpp:44 (most recent call first):\nframe #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0xae (0x7c12e295300e in /opt/conda/lib/python3.10/site-packages/torch/lib/libc10.so)\nframe #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) + 0xf3 (0x7c12e29191cf in /opt/conda/lib/python3.10/site-packages/torch/lib/libc10.so)\nframe #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x3f2 (0x7c12e29de722 in /opt/conda/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)\nframe #3: void causal_conv1d_update_launch<64, 4, float, float>(ConvParamsBase&, CUstream_st*) + 0x88 (0x7c124eece408 in /opt/conda/lib/python3.10/site-packages/causal_conv1d_cuda.cpython-310-x86_64-linux-gnu.so)\nframe #4: void causal_conv1d_update_cuda<float, float>(ConvParamsBase&, CUstream_st*) + 0x1c5 (0x7c124eece6e5 in /opt/conda/lib/python3.10/site-packages/causal_conv1d_cuda.cpython-310-x86_64-linux-gnu.so)\nframe #5: causal_conv1d_update(at::Tensor const&, at::Tensor const&, at::Tensor const&, c10::optional<at::Tensor> const&, bool) + 0x64f (0x7c124ee905af in /opt/conda/lib/python3.10/site-packages/causal_conv1d_cuda.cpython-310-x86_64-linux-gnu.so)\nframe #6: <unknown function> + 0x2ce0d (0x7c124ee96e0d in /opt/conda/lib/python3.10/site-packages/causal_conv1d_cuda.cpython-310-x86_64-linux-gnu.so)\nframe #7: <unknown function> + 0x3863a (0x7c124eea263a in /opt/conda/lib/python3.10/site-packages/causal_conv1d_cuda.cpython-310-x86_64-linux-gnu.so)\nframe #8: <unknown function> + 0x144516 (0x5d20bc8ca516 in /opt/conda/bin/python3.10)\nframe #9: _PyObject_MakeTpCall + 0x26b (0x5d20bc8c3a6b in /opt/conda/bin/python3.10)\nframe #10: _PyEval_EvalFrameDefault + 0x54a6 (0x5d20bc8bf9d6 in /opt/conda/bin/python3.10)\nframe #11: _PyFunction_Vectorcall + 0x6c (0x5d20bc8ca99c in /opt/conda/bin/python3.10)\nframe #12: _PyEval_EvalFrameDefault + 0x320 (0x5d20bc8ba850 in /opt/conda/bin/python3.10)\nframe #13: <unknown function> + 0x1504f2 (0x5d20bc8d64f2 in /opt/conda/bin/python3.10)\nframe #14: _PyEval_EvalFrameDefault + 0x4c12 (0x5d20bc8bf142 in /opt/conda/bin/python3.10)\nframe #15: <unknown function> + 0x1504f2 (0x5d20bc8d64f2 in /opt/conda/bin/python3.10)\nframe #16: PyObject_Call + 0xbc (0x5d20bc8d6e8c in /opt/conda/bin/python3.10)\nframe #17: _PyEval_EvalFrameDefault + 0x2d80 (0x5d20bc8bd2b0 in /opt/conda/bin/python3.10)\nframe #18: _PyFunction_Vectorcall + 0x6c (0x5d20bc8ca99c in /opt/conda/bin/python3.10)\nframe #19: _PyObject_FastCallDictTstate + 0x187 (0x5d20bc8c3007 in /opt/conda/bin/python3.10)\nframe #20: _PyObject_Call_Prepend + 0x69 (0x5d20bc8d4ba9 in /opt/conda/bin/python3.10)\nframe #21: <unknown function> + 0x2114c9 (0x5d20bc9974c9 in /opt/conda/bin/python3.10)\nframe #22: _PyObject_MakeTpCall + 0x26b (0x5d20bc8c3a6b in /opt/conda/bin/python3.10)\nframe #23: _PyEval_EvalFrameDefault + 0x5709 (0x5d20bc8bfc39 in /opt/conda/bin/python3.10)\nframe #24: <unknown function> + 0x1504f2 (0x5d20bc8d64f2 in /opt/conda/bin/python3.10)\nframe #25: PyObject_Call + 0xbc (0x5d20bc8d6e8c in /opt/conda/bin/python3.10)\nframe #26: _PyEval_EvalFrameDefault + 0x2d80 (0x5d20bc8bd2b0 in /opt/conda/bin/python3.10)\nframe #27: _PyFunction_Vectorcall + 0x6c (0x5d20bc8ca99c in /opt/conda/bin/python3.10)\nframe #28: _PyObject_FastCallDictTstate + 0x187 (0x5d20bc8c3007 in /opt/conda/bin/python3.10)\nframe #29: _PyObject_Call_Prepend + 0x69 (0x5d20bc8d4ba9 in /opt/conda/bin/python3.10)\nframe #30: <unknown function> + 0x2114c9 (0x5d20bc9974c9 in /opt/conda/bin/python3.10)\nframe #31: _PyObject_MakeTpCall + 0x26b (0x5d20bc8c3a6b in /opt/conda/bin/python3.10)\nframe #32: _PyEval_EvalFrameDefault + 0x5709 (0x5d20bc8bfc39 in /opt/conda/bin/python3.10)\nframe #33: <unknown function> + 0x1504f2 (0x5d20bc8d64f2 in /opt/conda/bin/python3.10)\nframe #34: PyObject_Call + 0xbc (0x5d20bc8d6e8c in /opt/conda/bin/python3.10)\nframe #35: _PyEval_EvalFrameDefault + 0x2d80 (0x5d20bc8bd2b0 in /opt/conda/bin/python3.10)\nframe #36: _PyFunction_Vectorcall + 0x6c (0x5d20bc8ca99c in /opt/conda/bin/python3.10)\nframe #37: _PyObject_FastCallDictTstate + 0x187 (0x5d20bc8c3007 in /opt/conda/bin/python3.10)\nframe #38: _PyObject_Call_Prepend + 0x69 (0x5d20bc8d4ba9 in /opt/conda/bin/python3.10)\nframe #39: <unknown function> + 0x2114c9 (0x5d20bc9974c9 in /opt/conda/bin/python3.10)\nframe #40: _PyObject_MakeTpCall + 0x26b (0x5d20bc8c3a6b in /opt/conda/bin/python3.10)\nframe #41: _PyEval_EvalFrameDefault + 0x5709 (0x5d20bc8bfc39 in /opt/conda/bin/python3.10)\nframe #42: <unknown function> + 0x1504f2 (0x5d20bc8d64f2 in /opt/conda/bin/python3.10)\nframe #43: PyObject_Call + 0xbc (0x5d20bc8d6e8c in /opt/conda/bin/python3.10)\nframe #44: _PyEval_EvalFrameDefault + 0x2d80 (0x5d20bc8bd2b0 in /opt/conda/bin/python3.10)\nframe #45: _PyFunction_Vectorcall + 0x6c (0x5d20bc8ca99c in /opt/conda/bin/python3.10)\nframe #46: _PyObject_FastCallDictTstate + 0x187 (0x5d20bc8c3007 in /opt/conda/bin/python3.10)\nframe #47: _PyObject_Call_Prepend + 0x69 (0x5d20bc8d4ba9 in /opt/conda/bin/python3.10)\nframe #48: <unknown function> + 0x2114c9 (0x5d20bc9974c9 in /opt/conda/bin/python3.10)\nframe #49: _PyObject_MakeTpCall + 0x26b (0x5d20bc8c3a6b in /opt/conda/bin/python3.10)\nframe #50: _PyEval_EvalFrameDefault + 0x5709 (0x5d20bc8bfc39 in /opt/conda/bin/python3.10)\nframe #51: _PyFunction_Vectorcall + 0x6c (0x5d20bc8ca99c in /opt/conda/bin/python3.10)\nframe #52: _PyEval_EvalFrameDefault + 0x13ca (0x5d20bc8bb8fa in /opt/conda/bin/python3.10)\nframe #53: _PyFunction_Vectorcall + 0x6c (0x5d20bc8ca99c in /opt/conda/bin/python3.10)\nframe #54: PyObject_Call + 0xbc (0x5d20bc8d6e8c in /opt/conda/bin/python3.10)\nframe #55: _PyEval_EvalFrameDefault + 0x2d80 (0x5d20bc8bd2b0 in /opt/conda/bin/python3.10)\nframe #56: _PyFunction_Vectorcall + 0x6c (0x5d20bc8ca99c in /opt/conda/bin/python3.10)\nframe #57: _PyEval_EvalFrameDefault + 0x13ca (0x5d20bc8bb8fa in /opt/conda/bin/python3.10)\nframe #58: _PyFunction_Vectorcall + 0x6c (0x5d20bc8ca99c in /opt/conda/bin/python3.10)\nframe #59: PyObject_Call + 0xbc (0x5d20bc8d6e8c in /opt/conda/bin/python3.10)\nframe #60: _PyEval_EvalFrameDefault + 0x2d80 (0x5d20bc8bd2b0 in /opt/conda/bin/python3.10)\nframe #61: _PyFunction_Vectorcall + 0x6c (0x5d20bc8ca99c in /opt/conda/bin/python3.10)\nframe #62: PyObject_Call + 0xbc (0x5d20bc8d6e8c in /opt/conda/bin/python3.10)\nframe #63: _PyEval_EvalFrameDefault + 0x2d80 (0x5d20bc8bd2b0 in /opt/conda/bin/python3.10)\n"],"ename":"RuntimeError","evalue":"CUDA error: no kernel image is available for execution on the device\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n\nException raised from c10_cuda_check_implementation at /usr/local/src/pytorch/c10/cuda/CUDAException.cpp:44 (most recent call first):\nframe #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0xae (0x7c12e295300e in /opt/conda/lib/python3.10/site-packages/torch/lib/libc10.so)\nframe #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) + 0xf3 (0x7c12e29191cf in /opt/conda/lib/python3.10/site-packages/torch/lib/libc10.so)\nframe #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x3f2 (0x7c12e29de722 in /opt/conda/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)\nframe #3: void causal_conv1d_update_launch<64, 4, float, float>(ConvParamsBase&, CUstream_st*) + 0x88 (0x7c124eece408 in /opt/conda/lib/python3.10/site-packages/causal_conv1d_cuda.cpython-310-x86_64-linux-gnu.so)\nframe #4: void causal_conv1d_update_cuda<float, float>(ConvParamsBase&, CUstream_st*) + 0x1c5 (0x7c124eece6e5 in /opt/conda/lib/python3.10/site-packages/causal_conv1d_cuda.cpython-310-x86_64-linux-gnu.so)\nframe #5: causal_conv1d_update(at::Tensor const&, at::Tensor const&, at::Tensor const&, c10::optional<at::Tensor> const&, bool) + 0x64f (0x7c124ee905af in /opt/conda/lib/python3.10/site-packages/causal_conv1d_cuda.cpython-310-x86_64-linux-gnu.so)\nframe #6: <unknown function> + 0x2ce0d (0x7c124ee96e0d in /opt/conda/lib/python3.10/site-packages/causal_conv1d_cuda.cpython-310-x86_64-linux-gnu.so)\nframe #7: <unknown function> + 0x3863a (0x7c124eea263a in /opt/conda/lib/python3.10/site-packages/causal_conv1d_cuda.cpython-310-x86_64-linux-gnu.so)\nframe #8: <unknown function> + 0x144516 (0x5d20bc8ca516 in /opt/conda/bin/python3.10)\nframe #9: _PyObject_MakeTpCall + 0x26b (0x5d20bc8c3a6b in /opt/conda/bin/python3.10)\nframe #10: _PyEval_EvalFrameDefault + 0x54a6 (0x5d20bc8bf9d6 in /opt/conda/bin/python3.10)\nframe #11: _PyFunction_Vectorcall + 0x6c (0x5d20bc8ca99c in /opt/conda/bin/python3.10)\nframe #12: _PyEval_EvalFrameDefault + 0x320 (0x5d20bc8ba850 in /opt/conda/bin/python3.10)\nframe #13: <unknown function> + 0x1504f2 (0x5d20bc8d64f2 in /opt/conda/bin/python3.10)\nframe #14: _PyEval_EvalFrameDefault + 0x4c12 (0x5d20bc8bf142 in /opt/conda/bin/python3.10)\nframe #15: <unknown function> + 0x1504f2 (0x5d20bc8d64f2 in /opt/conda/bin/python3.10)\nframe #16: PyObject_Call + 0xbc (0x5d20bc8d6e8c in /opt/conda/bin/python3.10)\nframe #17: _PyEval_EvalFrameDefault + 0x2d80 (0x5d20bc8bd2b0 in /opt/conda/bin/python3.10)\nframe #18: _PyFunction_Vectorcall + 0x6c (0x5d20bc8ca99c in /opt/conda/bin/python3.10)\nframe #19: _PyObject_FastCallDictTstate + 0x187 (0x5d20bc8c3007 in /opt/conda/bin/python3.10)\nframe #20: _PyObject_Call_Prepend + 0x69 (0x5d20bc8d4ba9 in /opt/conda/bin/python3.10)\nframe #21: <unknown function> + 0x2114c9 (0x5d20bc9974c9 in /opt/conda/bin/python3.10)\nframe #22: _PyObject_MakeTpCall + 0x26b (0x5d20bc8c3a6b in /opt/conda/bin/python3.10)\nframe #23: _PyEval_EvalFrameDefault + 0x5709 (0x5d20bc8bfc39 in /opt/conda/bin/python3.10)\nframe #24: <unknown function> + 0x1504f2 (0x5d20bc8d64f2 in /opt/conda/bin/python3.10)\nframe #25: PyObject_Call + 0xbc (0x5d20bc8d6e8c in /opt/conda/bin/python3.10)\nframe #26: _PyEval_EvalFrameDefault + 0x2d80 (0x5d20bc8bd2b0 in /opt/conda/bin/python3.10)\nframe #27: _PyFunction_Vectorcall + 0x6c (0x5d20bc8ca99c in /opt/conda/bin/python3.10)\nframe #28: _PyObject_FastCallDictTstate + 0x187 (0x5d20bc8c3007 in /opt/conda/bin/python3.10)\nframe #29: _PyObject_Call_Prepend + 0x69 (0x5d20bc8d4ba9 in /opt/conda/bin/python3.10)\nframe #30: <unknown function> + 0x2114c9 (0x5d20bc9974c9 in /opt/conda/bin/python3.10)\nframe #31: _PyObject_MakeTpCall + 0x26b (0x5d20bc8c3a6b in /opt/conda/bin/python3.10)\nframe #32: _PyEval_EvalFrameDefault + 0x5709 (0x5d20bc8bfc39 in /opt/conda/bin/python3.10)\nframe #33: <unknown function> + 0x1504f2 (0x5d20bc8d64f2 in /opt/conda/bin/python3.10)\nframe #34: PyObject_Call + 0xbc (0x5d20bc8d6e8c in /opt/conda/bin/python3.10)\nframe #35: _PyEval_EvalFrameDefault + 0x2d80 (0x5d20bc8bd2b0 in /opt/conda/bin/python3.10)\nframe #36: _PyFunction_Vectorcall + 0x6c (0x5d20bc8ca99c in /opt/conda/bin/python3.10)\nframe #37: _PyObject_FastCallDictTstate + 0x187 (0x5d20bc8c3007 in /opt/conda/bin/python3.10)\nframe #38: _PyObject_Call_Prepend + 0x69 (0x5d20bc8d4ba9 in /opt/conda/bin/python3.10)\nframe #39: <unknown function> + 0x2114c9 (0x5d20bc9974c9 in /opt/conda/bin/python3.10)\nframe #40: _PyObject_MakeTpCall + 0x26b (0x5d20bc8c3a6b in /opt/conda/bin/python3.10)\nframe #41: _PyEval_EvalFrameDefault + 0x5709 (0x5d20bc8bfc39 in /opt/conda/bin/python3.10)\nframe #42: <unknown function> + 0x1504f2 (0x5d20bc8d64f2 in /opt/conda/bin/python3.10)\nframe #43: PyObject_Call + 0xbc (0x5d20bc8d6e8c in /opt/conda/bin/python3.10)\nframe #44: _PyEval_EvalFrameDefault + 0x2d80 (0x5d20bc8bd2b0 in /opt/conda/bin/python3.10)\nframe #45: _PyFunction_Vectorcall + 0x6c (0x5d20bc8ca99c in /opt/conda/bin/python3.10)\nframe #46: _PyObject_FastCallDictTstate + 0x187 (0x5d20bc8c3007 in /opt/conda/bin/python3.10)\nframe #47: _PyObject_Call_Prepend + 0x69 (0x5d20bc8d4ba9 in /opt/conda/bin/python3.10)\nframe #48: <unknown function> + 0x2114c9 (0x5d20bc9974c9 in /opt/conda/bin/python3.10)\nframe #49: _PyObject_MakeTpCall + 0x26b (0x5d20bc8c3a6b in /opt/conda/bin/python3.10)\nframe #50: _PyEval_EvalFrameDefault + 0x5709 (0x5d20bc8bfc39 in /opt/conda/bin/python3.10)\nframe #51: _PyFunction_Vectorcall + 0x6c (0x5d20bc8ca99c in /opt/conda/bin/python3.10)\nframe #52: _PyEval_EvalFrameDefault + 0x13ca (0x5d20bc8bb8fa in /opt/conda/bin/python3.10)\nframe #53: _PyFunction_Vectorcall + 0x6c (0x5d20bc8ca99c in /opt/conda/bin/python3.10)\nframe #54: PyObject_Call + 0xbc (0x5d20bc8d6e8c in /opt/conda/bin/python3.10)\nframe #55: _PyEval_EvalFrameDefault + 0x2d80 (0x5d20bc8bd2b0 in /opt/conda/bin/python3.10)\nframe #56: _PyFunction_Vectorcall + 0x6c (0x5d20bc8ca99c in /opt/conda/bin/python3.10)\nframe #57: _PyEval_EvalFrameDefault + 0x13ca (0x5d20bc8bb8fa in /opt/conda/bin/python3.10)\nframe #58: _PyFunction_Vectorcall + 0x6c (0x5d20bc8ca99c in /opt/conda/bin/python3.10)\nframe #59: PyObject_Call + 0xbc (0x5d20bc8d6e8c in /opt/conda/bin/python3.10)\nframe #60: _PyEval_EvalFrameDefault + 0x2d80 (0x5d20bc8bd2b0 in /opt/conda/bin/python3.10)\nframe #61: _PyFunction_Vectorcall + 0x6c (0x5d20bc8ca99c in /opt/conda/bin/python3.10)\nframe #62: PyObject_Call + 0xbc (0x5d20bc8d6e8c in /opt/conda/bin/python3.10)\nframe #63: _PyEval_EvalFrameDefault + 0x2d80 (0x5d20bc8bd2b0 in /opt/conda/bin/python3.10)\n","output_type":"error"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}